% Chapter Template

\chapter{Software requirement specification} % Main chapter title

\label{ChapterX} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{ \emph{Software requirement specification}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction}



\subsection{Purpose}

The software requirement specification should provide all needed information to develop the context extraction framework and define all delivery objects. All interfaces to external components, input and output data, deployment considerations and quality attribute should be well defined within this document.


\subsection{Scope}


The context extraction framework will perform automated text extraction on a set of HTML test data with two to three different text extraction algorithms. The performance of each algorithm is measured and an output file with the measured results is generated.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{General description}

\subsection{Operating Environment}

The operation environment for the text extraction framework is defined in this section.

\subsubsection{Local environment}

\begin{tabular}{| p{3cm} | p{3cm} |}
	\hline
	Ubuntu & 12.04 \\
	JDK & 1.7.X  \\ \hline
	Gradle & 1.11 \\ \hline
	Eclipse Keppler & 2.X \\ \hline
	git & 1.9.X \\ \hline
	python & 2.7.X \\ \hline

\end{tabular}


\subsubsection{Continuous Integration Environment}

\begin{tabular}{| p{3cm} | p{3cm} |}
	\hline
	Ubuntu & 12.04 \\ \hline
	Open JDK & 1.6.X  \\ \hline
	Open JDK & 1.7.X  \\ \hline
	Oracle JDK & 1.7.X \\ \hline
	Oracle JDK & 1.8.X  \\ \hline
	Gradle & 2.0 \\ \hline
	Travis CI &  \\ \hline
\end{tabular}



\subsection{Design and Implementation Constraints}

\subsubsection{User interface}
As parts of the text extraction framework may be implemented in a server environment at a later point in time and a user interface is not desired from the client so there will be no graphical user interface. The application is built, deployed and started by gradle. While the application is running, no interaction with the user is needed.


\section{System Features}

This section specifies all system features. Each feature is specified more close with multiple user stories but all important information such as external dependencies and output files are defined in this chapter. The related user stories are located in the planning section.  



\begin{landscape}

\subsection{Basic functionality}
Following diagram and text describes the basic functionality of the application.

\includegraphics[width=24cm]{Figures/App_overview.pdf}

There are two folders defined by a configuration flies which. The HTML folder contains plain HTML files of web pages. The content folder contains text files with the relevant content of the related HTML files. As soon as a test is started the HTML file and the text file are read and the HTML file is extracted and classified with all the available algorithms. The result of the classification is then compared to the text file with the relevant content and performance data is generated. This performance data is then analyzed with statistical methods. 

\end{landscape}



\subsection{Overview}

	\begin{tabular}{ | p{0.5cm} | p{9cm} |p{2cm} |p{2.5cm} |}
	\hline
	\textbf{ID}	& \textbf{Name} 									& \textbf{Chapter}    											& \textbf{Relevance}	\\ \hline
	f1  		& Read configuration 								& \ref{subsec:Read configuration}  								& needed 				\\ \hline
	f2  		& Create test 										& \ref{subsec:Create test}										& needed 				\\ \hline
	f3  		& Integration Justext algorithm 					& \ref{subsec:Integration Justext algorithm} 					& needed 				\\ \hline
	f4  		& Integration Boilerpipe algorithm 					& \ref{subsec:Integration Boilerpipe algorithm}  				& needed 				\\ \hline
	f5  		& Evaluation and Implementation RSS feed algorithm 	& \ref{subsec:Evaluation and Implementation RSS feed algorithm} & nice to have			\\ \hline
	f6  		& Evaluation of classification text 				& \ref{subsec:Evaluation of classification text}				& needed 				\\ \hline
	f7  		& Evaluation of classification blocks 				& \ref{subsec:Evaluation of classification blocks}	  			& nice to have			\\ \hline
	f8  		& Analyze data 										& \ref{subsec:Analyze data}										& needed 				\\ \hline
	\end{tabular} \\



\subsubsection{Read configuration}
\label{subsec:Read configuration}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Read configuration 				\\ \hline
	\textbf{Feature id} 		& f1 				\\ \hline
	\textbf{Description} 		& The text extraction framework is configurable with an external text file. The configuration file will contain following items:
							        \begin{itemize}
							        \item Path to folder with HTML files
							        \item Path to folder with text files
							        \item Path to folder with output files
							        \item Configuration for algorithms
							        \item etc.
						        \end{itemize} 
						        The configuration file location is defined as a relative path to the source directory and structured in a key value list: 

						        \lstinputlisting{Code/config_template.txt} \\ \hline
	\textbf{Relevance} 			& needed 			\\ \hline
	\textbf{Related stories} 	& tbd		\\ \hline
	\end{tabular} \\

\subsubsection{Create test}
\label{subsec:Create test}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Create test \\ \hline
	\textbf{Feature id} 		& f2 \\ \hline
	\textbf{Description} 		& A test contains two input files which are a HTML file and a text file. They are located in the directories defined by the configuration. As soon as the test framework finds an HTML and a text file with the same name, a new test is created, the files are read and the test is started.\\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\subsubsection{Integration Justext algorithm}
\label{subsec:Integration Justext algorithm}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Integration Justext algorithm \\ \hline
	\textbf{Feature id} 		& f3 \\ \hline
	\textbf{Description} 		& Justext is implemented in python so a service is needed to call the python script and get the extracted text or the extracted blocks.\\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\subsubsection{Integration Boilerpipe algorithm}
\label{subsec:Integration Boilerpipe algorithm}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Integration Boilerpipe algorithm \\ \hline
	\textbf{Feature id} 		& f4 \\ \hline
	\textbf{Description} 		& Boilerplate is implemented in Java so an interface is needed to call the Boilerplate component and get the extracted text or the extracted blocks.\\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\subsubsection{Evaluation and Implementation RSS feed algorithm}
\label{subsec:Evaluation and Implementation RSS feed algorithm}

\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Evaluation and implementation RSS feed algorithm \\ \hline
	\textbf{Feature id} 		& f5 \\ \hline
	\textbf{Description} 		& The basic idea of the RSS feed algorithm is to match the content of a HTML document with the related RSS feed and define the relevant content like that. This need to be evaluated, implemented and integrated into the text extraction framework  \\ \hline
	\textbf{Relevance} 			& nice to have\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\subsubsection{Evaluation of classification text}
\label{subsec:Evaluation of classification text}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Evaluation of classification \\ \hline
	\textbf{Feature id} 		& f6 \\ \hline
	\textbf{Description} 		& All the text extraction algorithms return an extracted document as text. This document needs to be checked for correctness. To do so the result from the algorithms is compared with the predefined content. This evaluation and classification is defined in more detail in section \ref{subsec:Evaluation of classification}.
								\begin{itemize}
							        \item Check each classified block from the algorithms if it's content can be found in the content file
							        \item Categorize text as boilerplate or content
							        \item Put the results into an output text file (structure output file: tbd)
						        \end{itemize} \\ \hline
	\textbf{Relevance} 			& needed\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\


\subsubsection{Evaluation of classification blocks}
\label{subsec:Evaluation of classification blocks}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Evaluation of classification blocks \\ \hline
	\textbf{Feature id} 		& f6 \\ \hline
	\textbf{Description} 		& A more detailed evaluation of the algorithms could be done if not only the text is classified but each block of an HTML file. To do so, the implementation of Justext and Boilerpipe have to be adapted that they return classified blocks instead of the extracted text. These blocks are then compared with the predefined content and classified. This evaluation and classification is defined in more detail in section \ref{subsec:Evaluation of classification}.
								\begin{itemize}
							        \item Check each classified block from the algorithms if it's content can be found in the content file
							        \item Categorize all blocks as boilerplate or content
							        \item Put the results into an output text file (structure output file: tbd)
						        \end{itemize} \\ \hline
	\textbf{Relevance} 			& nice to have\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\





\subsection{Analyze data}
\label{subsec:Analyze data}

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Analyze data \\ \hline
	\textbf{Feature id} 		& f7 \\ \hline
	\textbf{Description} 		&  From the results of the comparison several further values can be evaluated for a better understanding of the results. These values are described in more detail in section \ref{subsec:Analytical values}.
								    \\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

%    \item Presicion: $\frac{TP}{TP + FP}$
%    \item Recall/True positive rate (TPR): $\frac{TP}{TP + FN}$
%    \item false positive rate (FPR: $\frac{FP}{FP + TN}$
%    \item F-measure: $2* \frac{presicion * recall}{presicion + recall}$
%    \item Reciever Operation Characteristics (ROC): $TPR = f(FPR)$

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Visualize data \\ \hline
	\textbf{Feature id} 		& f8 \\ \hline
	\textbf{Description} 		& The calculated values from feature f8 are visualized in diagrams. (tbd: which tool)\\ \hline
	\textbf{Relevance} 			& tbd\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\


\subsection{Evaluation of classification}
\label{subsec:Evaluation of classification}


The general meaning of the expressions true positive, true negative, false positive and false negative related to the text extraction topic is shown in following table:

\begin{table}[h]
\begin{tabular}{|p{4cm} |p{5.5cm} |p{5.5cm} |}\hline
          								& \textbf{Classified as content} 	& \textbf{Classified as boilerplate} 	\\ \hline
\textbf{Acutal content} 				& True positive (TP)				& False negative(FN)					\\ \hline
\textbf{Actual boilerplate} 			& False positive (FP)       		& True negative (TN)				 	\\ \hline
\end{tabular}
\end{table}

When the results are compared based on words, the expressions are interpreted as follow.

 \begin{table}[h]
\begin{tabular}{|p{4cm} |p{5.5cm} |p{5.5cm} |}
\hline         								& \textbf{Classified as content} 				& \textbf{Classified as boilerplate} 					\\ \hline
\textbf{Acutal content} 				& Word classified as content by algorithm and is content		& Word classified as content by algorithm but is boilerplate		\\ \hline
\textbf{Actual boilerplate} 			& Word classified as content by algorithm but is boilerplate 	& Word classified as boilerplate by algorithm and is Boilerplate	\\ \hline
\end{tabular}
\end{table}

When the results are compared based on HTML blocks, the expressions are interpreted as follow.

 \begin{table}[h]
\begin{tabular}{|p{4cm} |p{5.5cm} |p{5.5cm} |}
\hline         							& \textbf{Classified as content} 								& \textbf{Classified as boilerplate} 								\\ \hline
\textbf{Acutal content} 				& Block is classified as content by algorithm and is content		& Block is classified as content by algorithm but is boilerplate		\\ \hline
\textbf{Actual boilerplate} 			& Block is classified as content by algorithm but is boilerplate 	& Block is classified as boilerplate by algorithm and is boilerplate	\\ \hline
\end{tabular}
\end{table}

To sum this up TP + FN is the correct outcome of the algorithm i.e. content classified as content and boilerplate as boilerplate and TN + FP on the other hand is the wrong outcome of the algorithm i.e. content classified as boilerplate and boilerplate as content.



\subsection{Analytical values}
\label{subsec:Analytical values}

In this paragraph we use the notion of objects instead of word/block.
The results of the comparison deliver basic characteristics which can be used to calculate statistical values which help to analyze the test outcome.
										
\textbf{ Sensitivity / Recall /True positive rate / TPR / Hitrate }

Recall is the probability that a relevant document is retrieved in a search which in our case is

\begin{equation}
 Recall =\frac{TP}{TP + FN}
\end{equation}

correct classified content objects divided by the sum of all actual objects.

\textbf{Precision / True negative rate / TNR} 


Precision is the probability that a retrieved document is relevant which in our case is

\begin{equation}
 Presicion = \frac{TP}{TP + FP}
\end{equation}

correct classified content objects divided by the sum of all objects classified as content.

\textbf{F-measure / F1-score / F-score} 

F-measure is the weighted harmonic mean of precision and recall which in our case is

\begin{equation}
Fmeasure =  2* \frac{presicion * recall}{presicion + recall}
\end{equation}

a measure of the test's accuracy.



\textbf{Fallout / False positive rate / FPR}

Fallout is the proportion of non-relevant objects that are retrieved, out of all non-relevant objects available which in our case is

\begin{equation}
Fallout = \frac{FP}{FP + TN}
\end{equation}

%\textbf{Accuracy}

%\begin{equation}
%Accuracy =  \frac{TP+FN}{TP+TN+FP+FN}
%\end{equation}


\section{External Interface Requirements}

\subsection{Boilerpipe}

The boilerpipe algorithm is implemented in Java and the documentation is found under
\url{https://code.google.com/p/boilerpipe/}.

\subsection{justext}

The justext algorithem is implemented in python and the documentation is found under \url{https://code.google.com/p/justext/}. It is not yet defined how it will be integrated into the text extraction framework. See risk analysis for further information (\ref{subsec:Integration Justext}.).