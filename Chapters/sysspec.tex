% Chapter Template

\chapter{Software requirement specification} % Main chapter title

\label{ChapterX} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{ \emph{Software requirement specification}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Introduction}



\subsection{Purpose}

The software requirement specification should provide all needed information to develop the context extraction framework and define all delivery objects. All interfaces to external components, input and output data, deployment considerations and quality attribute should be well defined within this document.


\subsection{Scope}


The context extraction framework will perform automated text extraction on a set of HTML test data with two to three different text extraction algorithms. The performance of each algorithm is measured and an output file with the measured results is generated.

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{General description}

\subsection{Operating Environment}

\subsubsection{Local environment}

\begin{tabular}{| p{3cm} | p{3cm} |}
	\hline
	JDK & 1.7.X  \\ \hline
	Gradle & 1.1 \\ \hline
	Eclipse Keppler & 2.X \\ \hline
	git & 1.9.X \\ \hline
	python & 2.7.X \\ \hline
\end{tabular}


\subsubsection{Continuous Integration Environment}

\begin{tabular}{| p{3cm} | p{3cm} |}
	\hline
	Open JDK & 1.6.X  \\ \hline
	Open JDK & 1.7.X  \\ \hline
	Oracle JDK & 1.7.X \\ \hline
	Oracle JDK & 1.8.X  \\ \hline
	Gradle & 1.1 \\ \hline
	Travis CI &  \\ \hline
\end{tabular}



\subsection{Design and Implementation Constraints}

\subsubsection{User interface}
As parts of the text extraction framework may be implemented in a server environment and a user interface is not gew√ºnscht from the client so there will be no graphical user interface. The application is built, deployed and started by gradle. While the application is running, no interaction with the user is needed.


\section{System Features}

This section specifies all system features. Each feature is specified more close with multiple user stories but all important information such as external dependencies and output files are defined in this chapter. The related user stories are located in the planning section.  

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Read configuration 				\\ \hline
	\textbf{Feature id} 		& f1 				\\ \hline
	\textbf{Description} 		& The text extraction framework is configurable with an external text file. The configuration file will contain following items:
							        \begin{itemize}
							        \item Path to folder with html files
							        \item Path to folder with text files
							        \item Path to folder with output files
							        \item Configuration for algorithms
							        \item etc.
						        \end{itemize} 
						        The configuration file location is defined as a relative path to the source directory and structured in a key value list: 

						        \lstinputlisting{Code/config_template.txt} \\ \hline
	\textbf{Relevance} 			& needed 			\\ \hline
	\textbf{Related stories} 	& tbd		\\ \hline
	\end{tabular} \\

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Create test \\ \hline
	\textbf{Feature id} 		& f2 \\ \hline
	\textbf{Description} 		& A test contains two input files which are a html file and a text file. They are located in the defined directories by the configuration. As soon as the test framework finds a html and a text file with the same name, a new test is created and the files are read.\\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Run test \\ \hline
	\textbf{Feature id} 		& f3 \\ \hline
	\textbf{Description} 		& A test is run as defined in the configuration file. The configuration file defines which algorithms are tested. The output of a test is a text file which contains the results. \\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Integrate Justext algorithm \\ \hline
	\textbf{Feature id} 		& f4 \\ \hline
	\textbf{Description} 		& The justext interface is providing a method with an html file as parameter and an extracted text as return value. \\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\


	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Integrate Boilerpipe algorithm \\ \hline
	\textbf{Feature id} 		& f5 \\ \hline
	\textbf{Description} 		& The Boilerplate interface is providing a method with an html file as parameter and an extracted text as return value. \\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Integrate RSS feed algorithm \\ \hline
	\textbf{Feature id} 		& f6 \\ \hline
	\textbf{Description} 		& The RSS feed algorithm interface is providing a method with an html file as parameter and an extracted text as return value. \\ \hline
	\textbf{Relevance} 			& nice to have\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Comparison of extracted text files \\ \hline
	\textbf{Feature id} 		& f7 \\ \hline
	\textbf{Description} 		& Each output file from the different algorithm needs to be compared to the text file with the actual content.
								\begin{itemize}
							        \item Split HTML document into blocks separated by HTML tags
							        \item Define which blocks are content and which are boilerplate based on the text file which defines the content
							        \item Define which blocks are content and which are boilerplate based on the output file of each text extraction algorithm
							        \item Compare the results and categorize all blocks as true negative or false positive
							        \item Put the results into an output text file (structure output file: tbd)
						        \end{itemize} \\ \hline
	\textbf{Relevance} 			& nice to have\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\


	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Analyze data \\ \hline
	\textbf{Feature id} 		& f8 \\ \hline
	\textbf{Description} 		&  From the results of the comparison several further values can be calculated. Some possible values are:
									\begin{itemize}
									    \item Presicion
									    \item Recall/True positive rate (TPR)
									    \item false positive rate (FPR)
									    \item F-measure
									    \item Reciever Operation Characteristics (ROC)
								    \end{itemize} 
								    \\ \hline
	\textbf{Relevance} 			& needed \\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

%    \item Presicion: $\frac{TP}{TP + FP}$
%    \item Recall/True positive rate (TPR): $\frac{TP}{TP + FN}$
%    \item false positive rate (FPR: $\frac{FP}{FP + TN}$
%    \item F-measure: $2* \frac{presicion * recall}{presicion + recall}$
%    \item Reciever Operation Characteristics (ROC): $TPR = f(FPR)$

	\begin{tabular}{ | p{3cm} | p{12cm} |}
	\hline
	\textbf{Name} 				& Visualize data \\ \hline
	\textbf{Feature id} 		& f9 \\ \hline
	\textbf{Description} 		& The calculated values from feature f8 are visualized in diagrams. (tbd: which tool)\\ \hline
	\textbf{Relevance} 			& tbd\\ \hline
	\textbf{Related stories} 	& tbd \\ \hline
	\end{tabular} \\

\section{External Interface Requirements}

\subsection{Boilerpipe}

The boilerpipe algorithm is already implemented in Java so it is easy to integrate. The API can be found under following link. 
\url{https://code.google.com/p/boilerpipe/}

Other useful links:

Getting started:
\url{http://code.google.com/p/boilerpipe/wiki/QuickStart}

javadoc extractor:
\url{http://boilerpipe.googlecode.com/svn/trunk/boilerpipe-core/javadoc/1.0/de/l3s/boilerpipe/extractors/ExtractorBase.html}


\subsection{justext}

The justext algorithem is implemented in python and it is not yet defined how it will be integrated into the text extraction framework. See risk analysis for further information.
The documentation can be found under following link: 

\url{https://code.google.com/p/justext/}

jython:
http://www.jython.org/
