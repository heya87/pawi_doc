% Chapter Template

\chapter{Problem statement} % Main chapter title

\label{Problem statement} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{\emph{Problem statement}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

This chapter describes the problem statement, as well as the topical environment in which the project takes place.


\section{Introduction}

This project is done on behalf of the company Layzapp. Layzapp is specialized in second-screen solutions. It is currently working on a mobile application which brings relevant data to a second screen during a TV show. The Internet is crawled to find relevant information about a certain topic. The outcome of this search is a certain number of web pages. The content of these web pages is made usable by removing irrelevant data, such as navigation elements, advertisement and login pages. Removing the HTML content is not a very hard task. But after this first process of removal there is still much irrelevant content left, for instance descriptions of further articles or advertisements. Removing this part is much more complicated. 

\section{Task}

As described in the introduction, irrelevant content, which is also called boilerplate, needs to be removed from a web page. There are already several algorithms which fulfill this task. To compare the performance of the known algorithms and contrast them to possible new algorithms, a test environment is required. The test environment needs to classify the quality of a text extraction performed by the different algorithms. For this purpose, each algorithm is fed with a certain amount of HTML content. The outcome is then inspected for its quality. 

 \section{Text extraction and algorithms}

 This chapter is a description of the text extraction subject and the known algorithms.

 \subsection{Text extraction}

 Text extraction or content extraction of web pages is a widely discussed field in research. There are several approaches to this field. The two main approaches are page segmentation via visual and DOM features and boilerplate removal. The main drawback of visual page segmentation is that at some point the web page needs to be rendered and processed as image. This task is very time-consuming and many resources are necessary to fulfill it. This project focuses on algorithms which work with boilerplate removal.
 The basic idea of boilerplate removal was first introduced with the BTE (Body Text Extraction) algorithm. The assumptions are the relevant part of the HTML content is usually a contiguous stretch, the density of HTML tags is lower in it that in boilerplate content. Hence, by breaking up the HTML page in single sections and counting the HTML tags, there is an area where the number of HTML tags do not increase. It is quite simple to define an objective function. One can expect that this is the article text. Unfortunately, BTE's performance is very limited, but it is still used to compare different extraction algorithms to each other. The two algorithms Boilerpipe and Justext improve the performance of BTE.

 \subsection{Boilerpipe}

 The Boilerpipe algorithm is based on the concept described in Kohlsch√ºtter's paper "Boilerplate Detection using Shallow Text Features". It uses a variate of HTML tags  to divide the HTML document into blocks. Each block is classified according to its shallow text features and to the classification of the  previous and the next blocks. Some examples for shallow text features are average word length, average sentence length or the absolute number of words. The features are described more closely in the paper.

 \subsection{Justext}

Justext uses similar features as Boilerplate but inspects the data for the presence of stop words as well. Some examples for stop words are "a", "and", "but", "how", "or", and "what". An article contains more stop words than boilerplate. Based on this information, a better classification can be achieved.

\subsection{Classification}

The main task of the application is to somehow classify the performance of the algorithms. The performance can be defined as how much of relevant text is classified as relevant and how much is classified as boilerplate. In information retrieval, these performances can be described in a confusion matrix.

\begin{table}[h]
\begin{tabular}{|p{4cm} |p{5.5cm} |p{5.5cm} |}\hline
          								& \textbf{Classified as content} 	& \textbf{Classified as boilerplate} 	\\ \hline
\textbf{Actual content} 				& True positive (TP)				& False negative(FN)					\\ \hline
\textbf{Actual boilerplate} 			& False positive (FP)       		& True negative (TN)				 	\\ \hline
\end{tabular}
\end{table}

\begin{itemize}
\item True positive is the amount of text which is relevant content and classified as content by the algorithm
\item False positive is the amount of text which is relevant content but classified as boilerplate by the algorithm 
\item True negative is the amount of text which is boilerplate and is classified as boilerplate by the algorithm
\item False negative is the amount of text which is boilerplate but is classified as content by the algorithm
\end{itemize}

These values are the basis for calculating  both the recall (also known as sensitivity) which is the fraction of relevant text that is retrieved and the precision which is the fraction of retrieved text that is relevant. These values, their dependencies and some more values are described more closely in the software requirement specification (\ref{subsec:Evaluation of classification}).

\section{Conclusion}

An application is needed which can be fed with HTML documents. These documents are then processed by text extraction algorithms. The outcome is then compared with the relevant content and classification values are calculated. Based on these values the performance of the algorithms can be compared. Possible strengths and weaknesses can be determined in this comparison.

